# ETL/ELT Builder - Plateforme Modulaire de Pipelines de Donn√©es

**Plateforme low-code/no-code** permettant de concevoir, configurer et ex√©cuter des pipelines ETL/ELT via une interface visuelle **drag & drop**, avec orchestration intelligente et int√©gration IA.

![ETL/ELT Builder Demo](https://via.placeholder.com/800x400?text=ETL%2FELT+Builder+Demo) *(Remplace par une capture d'√©cran ou un GIF de ton application)*

---

## üåü Caract√©ristiques Principales

| **Fonctionnalit√©**               | **Description**                                                                                     |
|-----------------------------------|-----------------------------------------------------------------------------------------------------|
| **Interface Drag & Drop**         | Canvas interactif inspir√© de **n8n** et **Databricks** pour une conception intuitive.               |
| **Modules Extensibles**          | Extracteurs, transformateurs et chargeurs pour diverses sources (SQL, APIs, fichiers, etc.).       |
| **Orchestration Intelligente**   | Moteur bas√© sur **Apache Airflow** pour planifier et ex√©cuter les pipelines.                         |
| **IA Int√©gr√©e**                  | Suggestions automatiques de transformations et optimisations.                                      |
| **Pr√©visualisation en Temps R√©el** | Visualisation des donn√©es √† chaque √©tape du pipeline.                                             |
| **Monitoring Avanc√©**            | Logs, m√©triques et alertes en temps r√©el avec **Prometheus & Grafana**.                            |
| **Conformit√© RGPD**              | Chiffrement, anonymisation et audit trail pour les donn√©es sensibles.                               |

---

## üõ† Stack Technologique

### **Frontend**
- **Framework** : [React 18+](https://reactjs.org/) avec [TypeScript](https://www.typescriptlang.org/)
- **Drag & Drop** : [React Flow](https://reactflow.dev/)
- **UI** : [Material-UI (MUI)](https://mui.com/)
- **State Management** : [Zustand](https://github.com/pmndrs/zustand)
- **Build Tool** : [Vite](https://vitejs.dev/)

### **Backend**
- **Framework** : [FastAPI](https://fastapi.tiangolo.com/) (Python 3.14)
- **Base de Donn√©es** : [PostgreSQL 15+](https://www.postgresql.org/) avec [TimescaleDB](https://www.timescale.com/)
- **Orchestration** : [Apache Airflow](https://airflow.apache.org/)
- **Cache** : [Redis](https://redis.io/)
- **Stockage** : [MinIO](https://min.io/)

### **Infrastructure**
- **Conteneurisation** : [Docker](https://www.docker.com/) & [Docker Compose](https://docs.docker.com/compose/)
- **Reverse Proxy** : [Nginx](https://www.nginx.com/)
- **Monitoring** : [Prometheus](https://prometheus.io/) + [Grafana](https://grafana.com/)

---

## üöÄ Installation Rapide

### **Pr√©requis**
- Docker & Docker Compose
- Node.js 18+ (pour le d√©veloppement frontend)
- Python 3.14 (pour le d√©veloppement backend)
- Git

### **1. Cloner le Projet**
```bash
git clone https://github.com/Alexweb97/pipeline-builder-ai.git
cd pipeline-builder-ai


### 1. Cloner le Projet

```bash
git clone https://github.com/Alexweb97/pipeline-buider-ai.git
cd pipeline-builder-ai
```

### 2. Configuration

```bash
# Copier les fichiers d'environnement
cp backend/.env.example backend/.env
cp frontend/.env.example frontend/.env

# √âditer les variables d'environnement
nano backend/.env  # Configurer DB, Redis, etc.
```

### 3. D√©marrer avec Docker Compose

```bash
# D√©marrer tous les services
docker-compose up -d

# V√©rifier que tout fonctionne
docker-compose ps

# Voir les logs
docker-compose logs -f
```

### 4. Initialiser la Base de Donn√©es

```bash
# Ex√©cuter les migrations
docker-compose exec backend alembic upgrade head

# Cr√©er un utilisateur admin
docker-compose exec backend python scripts/create_admin.py
```

### 5. Acc√©der √† l'Application (developpement)

- **Frontend**: http://localhost:3000
- **API Backend**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **Airflow**: http://localhost:8080 (user: admin, password: admin)
- **MinIO**: http://localhost:9001 (user: minioadmin, password: minioadmin)

## D√©veloppement Local

### Backend

```bash
cd backend

# Cr√©er un environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows

# Installer les d√©pendances
pip install -r requirements-dev.txt

# Lancer le serveur de d√©veloppement
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# Lancer Celery worker
celery -A app.workers.celery_app worker --loglevel=info

# Tests
pytest -v --cov=app tests/
```

### Frontend

```bash
cd frontend

# Installer les d√©pendances
npm install

# Lancer le serveur de d√©veloppement
npm run dev

# Build production
npm run build

# Tests
npm run test
```

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      FRONTEND LAYER                          ‚îÇ
‚îÇ  React + TypeScript + React Flow + Material-UI              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº HTTP/WebSocket
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                       API GATEWAY                            ‚îÇ
‚îÇ              FastAPI + Authentication + CORS                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     BACKEND SERVICES                         ‚îÇ
‚îÇ  Pipeline Manager | Execution Engine | AI/ML Service        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  ORCHESTRATION LAYER                         ‚îÇ
‚îÇ              Apache Airflow (Dynamic DAGs)                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     DATA LAYER                               ‚îÇ
‚îÇ  PostgreSQL (Metadata) | Redis (Cache) | MinIO (Storage)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

Pour plus de d√©tails, consultez [ARCHITECTURE.md](./ARCHITECTURE.md).

## Cr√©er votre Premier Pipeline

### Via l'Interface Web

1. Connectez-vous √† http://localhost:3000
2. Cliquez sur "Nouveau Pipeline"
3. Glissez-d√©posez des modules depuis la palette:
   - **Extracteur PostgreSQL**: Connectez-vous √† votre base de donn√©es
   - **Nettoyeur**: Supprimez les doublons et validez les donn√©es
   - **Chargeur S3**: Sauvegardez dans un bucket S3/MinIO
4. Connectez les modules avec des fl√®ches
5. Configurez chaque module via le panneau lat√©ral
6. Cliquez sur "Ex√©cuter" pour lancer le pipeline

### Via l'API

```bash
curl -X POST http://localhost:8000/api/v1/pipelines \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -H "Content-Type: application/json" \
  -d '{
    "name": "Customer Data Export",
    "nodes": [
      {
        "id": "extract-1",
        "type": "extractor",
        "module": "postgres",
        "config": {
          "connection_id": "conn-uuid",
          "query": "SELECT * FROM customers"
        }
      },
      {
        "id": "load-1",
        "type": "loader",
        "module": "s3",
        "config": {
          "bucket": "data-lake",
          "format": "parquet"
        }
      }
    ],
    "edges": [
      {"source": "extract-1", "target": "load-1"}
    ]
  }'
```

## Modules Disponibles

### Extracteurs (Sources)
- PostgreSQL, MySQL, MongoDB, SQLite
- REST API, GraphQL
- CSV, JSON, Excel, Parquet
- S3, Google Cloud Storage, Azure Blob
- Kafka, RabbitMQ

### Transformateurs
- **Cleaner**: D√©duplication, normalisation, validation
- **Aggregator**: Group by, pivot, window functions
- **Joiner**: Jointures de datasets
- **Filter**: Filtrage avec conditions
- **Enricher**: Enrichissement via APIs
- **ML Transformer**: Pr√©dictions, classification

### Chargeurs (Destinations)
- PostgreSQL, MySQL, MongoDB
- ClickHouse, DuckDB
- S3, MinIO
- Parquet, Delta Lake, Iceberg

Pour d√©velopper vos propres modules, consultez [docs/MODULES.md](./docs/MODULES.md).

## Tests

### Backend
```bash
cd backend

# Tests unitaires
pytest tests/unit/ -v

# Tests d'int√©gration
pytest tests/integration/ -v

# Tests E2E
pytest tests/e2e/ -v

# Tous les tests avec coverage
pytest --cov=app --cov-report=html tests/
```

### Frontend
```bash
cd frontend

# Tests unitaires
npm run test:unit

# Tests d'int√©gration
npm run test:integration

# Coverage
npm run test:coverage
```

## D√©ploiement

### Docker Compose (Recommand√© pour commencer)

```bash
# Production
docker-compose -f infrastructure/docker/docker-compose.prod.yml up -d

# Staging
docker-compose -f infrastructure/docker/docker-compose.staging.yml up -d
```

### Kubernetes

```bash
cd infrastructure/kubernetes

# Cr√©er le namespace
kubectl apply -f namespace.yaml

# D√©ployer les services
kubectl apply -f .

# V√©rifier le d√©ploiement
kubectl get pods -n etl-builder
```

Pour plus de d√©tails, consultez [docs/DEPLOYMENT.md](./docs/DEPLOYMENT.md).

## Documentation

- [Architecture](./ARCHITECTURE.md) - Vue d'ensemble de l'architecture
- [Database Schema](./DATABASE_SCHEMA.md) - Sch√©ma de base de donn√©es
- [Project Structure](./PROJECT_STRUCTURE.md) - Structure du projet
- [API Documentation](./docs/API.md) - Documentation de l'API REST
- [Module Development](./docs/MODULES.md) - Cr√©er des modules personnalis√©s


### Workflow

1. Fork le projet
2. Cr√©ez une branche feature (`git checkout -b feature/AmazingFeature`)
3. Committez vos changements (`git commit -m 'feat: add amazing feature'`)
4. Pushez vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrez une Pull Request

### Standards de Code

- **Backend**: Black, isort, flake8, mypy
- **Frontend**: ESLint, Prettier
- **Commits**: Conventional Commits
- **Tests**: Coverage > 80%

## Support

- **Issues**: [GitHub Issues](https://github.com/Alexweb97/pipeline-buider-ai/issues)
- **Discussions**: [GitHub Discussions](https://github.com/Alexweb97/pipeline-buider-ai/discussions)
- **Email**: alexandretoto.dev@gmail.com

## Roadmap

### Phase 1: MVP (Q1 2025)
- ‚úÖ Architecture de base
- ‚úÖ Interface drag & drop
- ‚úÖ Modules de base (extracteurs, transformateurs, chargeurs)
- üîÑ Ex√©cution avec Airflow
- üîÑ Authentication & RBAC

### Phase 2: Am√©lioration (Q2 2025)
- ‚è≥ Pr√©visualisation des donn√©es
- ‚è≥ Suggestions IA
- ‚è≥ Monitoring avanc√©
- ‚è≥ 20+ modules

### Phase 3: Production (Q3 2025)
- ‚è≥ Optimisations performance
- ‚è≥ Conformit√© RGPD compl√®te
- ‚è≥ Documentation compl√®te
- ‚è≥ CI/CD production

## Licence

Ce projet est sous licence MIT. Voir [LICENSE](./LICENSE) pour plus de d√©tails.

## Cr√©dits

D√©velopp√© avec ‚ù§Ô∏è par Alexweb97.

### Technologies Utilis√©es

- [React](https://react.dev/)
- [FastAPI](https://fastapi.tiangolo.com/)
- [Apache Airflow](https://airflow.apache.org/)
- [React Flow](https://reactflow.dev/)
- [Material-UI](https://mui.com/)
- [PostgreSQL](https://www.postgresql.org/)
- [MinIO](https://min.io/)

---

**Note**: Ce projet est en d√©veloppement actif. Les fonctionnalit√©s et l'API peuvent changer.
